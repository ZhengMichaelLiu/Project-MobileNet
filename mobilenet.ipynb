{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on the GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "EPOCHS = 50\n",
    "drop_out_rate = 0.3\n",
    "NUM_CLASS = 10\n",
    "schedule_step = 20\n",
    "learning_rate_initial = 0.001\n",
    "gamma_val = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "train_transform = transforms.Compose([transforms.RandomRotation(5),\n",
    "                                      transforms.RandomHorizontalFlip(0.3),\n",
    "                                      transforms.RandomVerticalFlip(0.05),\n",
    "                                      transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                                           std = [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                                          std = [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "# load data\n",
    "train_set = torchvision.datasets.CIFAR10(root = './data', train = True,\n",
    "                                         download = True, transform = train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, \n",
    "                                           shuffle = True, num_workers = 4)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root = './data', train = False, \n",
    "                                        download = True, transform = test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, \n",
    "                                          shuffle = False, num_workers = 4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up MobileNet \n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 2, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 32)\n",
    "        self.relu1 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_dw1 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1, groups = 32, bias = False)\n",
    "        self.bn_dw1 = nn.BatchNorm2d(num_features = 32)\n",
    "        self.relu_dw1 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw1 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw1 = nn.BatchNorm2d(num_features = 64)\n",
    "        self.relu_pw1 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_dw2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 2, padding = 1, groups = 64, bias = False)\n",
    "        self.bn_dw2 = nn.BatchNorm2d(num_features = 64)\n",
    "        self.relu_dw2 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw2 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw2 = nn.BatchNorm2d(num_features = 128)\n",
    "        self.relu_pw2 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_dw3 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 1, groups = 128, bias = False)\n",
    "        self.bn_dw3 = nn.BatchNorm2d(num_features = 128)\n",
    "        self.relu_dw3 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw3 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw3 = nn.BatchNorm2d(num_features = 128)\n",
    "        self.relu_pw3 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_dw4 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 2, padding = 1, groups = 128, bias = False)\n",
    "        self.bn_dw4 = nn.BatchNorm2d(num_features = 128)\n",
    "        self.relu_dw4 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw4 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw4 = nn.BatchNorm2d(num_features = 256)\n",
    "        self.relu_pw4 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_dw5 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1, groups = 256, bias = False)\n",
    "        self.bn_dw5 = nn.BatchNorm2d(num_features = 256)\n",
    "        self.relu_dw5 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw5 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw5 = nn.BatchNorm2d(num_features = 256)\n",
    "        self.relu_pw5 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_dw6 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 2, padding = 1, groups = 256, bias = False)\n",
    "        self.bn_dw6 = nn.BatchNorm2d(num_features = 256)\n",
    "        self.relu_dw6 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw6 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw6 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_pw6 = nn.ReLU(inplace = True)\n",
    "\n",
    "        # 5x\n",
    "        # 7\n",
    "        self.conv_dw7 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, groups = 512, bias = False)\n",
    "        self.bn_dw7 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_dw7 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw7 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw7 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_pw7 = nn.ReLU(inplace = True)\n",
    "\n",
    "        # 8\n",
    "        self.conv_dw8 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, groups = 512, bias = False)\n",
    "        self.bn_dw8 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_dw8 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw8 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw8 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_pw8 = nn.ReLU(inplace = True)\n",
    "\n",
    "        # 9\n",
    "        self.conv_dw9 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, groups = 512, bias = False)\n",
    "        self.bn_dw9 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_dw9 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw9 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw9 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_pw9 = nn.ReLU(inplace = True)\n",
    "\n",
    "        # 10\n",
    "        self.conv_dw10 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, groups = 512, bias = False)\n",
    "        self.bn_dw10 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_dw10 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw10 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw10 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_pw10 = nn.ReLU(inplace = True)\n",
    "\n",
    "        # 11\n",
    "        self.conv_dw11 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, groups = 512, bias = False)\n",
    "        self.bn_dw11 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_dw11 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw11 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw11 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_pw11 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_dw12 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 2, padding = 1, groups = 512, bias = False)\n",
    "        self.bn_dw12 = nn.BatchNorm2d(num_features = 512)\n",
    "        self.relu_dw12 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw12 = nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw12 = nn.BatchNorm2d(num_features = 1024)\n",
    "        self.relu_pw12 = nn.ReLU(inplace = True)\n",
    "\n",
    "        # paper is wrong here\n",
    "        self.conv_dw13 = nn.Conv2d(in_channels = 1024, out_channels = 1024, kernel_size = 3, stride = 1, padding = 1, groups = 1024, bias = False)\n",
    "        self.bn_dw13 = nn.BatchNorm2d(num_features = 1024)\n",
    "        self.relu_dw13 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv_pw13 = nn.Conv2d(in_channels = 1024, out_channels = 1024, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
    "        self.bn_pw13 = nn.BatchNorm2d(num_features = 1024)\n",
    "        self.relu_pw13 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size = 7, padding = 0)\n",
    "\n",
    "        self.linear = nn.Linear(1024, NUM_CLASS)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu_pw1(self.bn_pw1(self.conv_pw1(self.relu_dw1(self.bn_dw1(self.conv_dw1(x))))))\n",
    "        x = self.relu_pw2(self.bn_pw2(self.conv_pw2(self.relu_dw2(self.bn_dw2(self.conv_dw2(x))))))\n",
    "        x = self.relu_pw3(self.bn_pw3(self.conv_pw3(self.relu_dw3(self.bn_dw3(self.conv_dw3(x))))))\n",
    "        x = self.relu_pw4(self.bn_pw4(self.conv_pw4(self.relu_dw4(self.bn_dw4(self.conv_dw4(x))))))\n",
    "        x = self.relu_pw5(self.bn_pw5(self.conv_pw5(self.relu_dw5(self.bn_dw5(self.conv_dw5(x))))))\n",
    "        x = self.relu_pw6(self.bn_pw6(self.conv_pw6(self.relu_dw6(self.bn_dw6(self.conv_dw6(x))))))\n",
    "        x = self.relu_pw7(self.bn_pw7(self.conv_pw7(self.relu_dw7(self.bn_dw7(self.conv_dw7(x))))))\n",
    "        x = self.relu_pw8(self.bn_pw8(self.conv_pw8(self.relu_dw8(self.bn_dw8(self.conv_dw8(x))))))\n",
    "        x = self.relu_pw9(self.bn_pw9(self.conv_pw9(self.relu_dw9(self.bn_dw9(self.conv_dw9(x))))))\n",
    "        x = self.relu_pw10(self.bn_pw10(self.conv_pw10(self.relu_dw10(self.bn_dw10(self.conv_dw10(x))))))\n",
    "        x = self.relu_pw11(self.bn_pw11(self.conv_pw11(self.relu_dw11(self.bn_dw11(self.conv_dw11(x))))))\n",
    "        x = self.relu_pw12(self.bn_pw12(self.conv_pw12(self.relu_dw12(self.bn_dw12(self.conv_dw12(x))))))\n",
    "        x = self.relu_pw13(self.bn_pw13(self.conv_pw13(self.relu_dw13(self.bn_dw13(self.conv_dw13(x))))))\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network and send to GPU\n",
    "mobilenet = MobileNet()\n",
    "mobilenet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mobilenet.parameters(), lr = learning_rate_initial)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = schedule_step, gamma = gamma_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# Train the data\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch: \", epoch + 1)\n",
    "    mobilenet.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = mobilenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    running_loss /= len(train_loader)\n",
    "    train_loss_list.append(running_loss)\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss))\n",
    "    \n",
    "    mobilenet.eval()\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            outputs = mobilenet(Variable(images))\n",
    "            i, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            outputs = mobilenet(Variable(images))\n",
    "            i, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    train_acc_list.append(100 * train_correct / train_total)  \n",
    "    test_acc_list.append(100 * correct / total)\n",
    "    print('Training Accuracy of current epoch: %.3f %%' % (100 * train_correct / train_total))\n",
    "    print('Testing Accuracy of current epoch: %.3f %%' % (100 * correct / total))\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.title('Training Loss Plot of Each Epoch')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc_list)\n",
    "plt.title('Training Accuracy Plot of Each Epoch')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test_acc_list)\n",
    "plt.title('Test Accuracy Plot of Each Epoch')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
